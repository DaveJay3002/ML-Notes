The learning rate (α\alphaα) is a hyperparameter that determines the size of the steps taken towards the minimum of the cost function. If the learning rate is too small, convergence will be slow; if it’s too large, it may overshoot the minimum or diverge.

### Learning rate is too small
![[Pasted image 20241004154352.png]]

### Learning rate is too large
![[Pasted image 20241004154508.png]]